\chapter{Estado del Arte}\label{chapter:state-of-the-art}

El cáncer de piel es el más frecuente del mundo \textit{annadir cita} . A diferencia de muchos otros tipos de cáncer que se 
desarrollan internamente, el cáncer de piel se forma externamente y suele ser visible, lo que lo convierte en el "cáncer que se ve". Esta visibilidad subraya 
la importancia de los exámenes de la piel, tanto realizados por uno mismo como por dermatólogos.El diagnóstico y el tratamiento oportunos son primordiales. 
La mayoría de los casos de cáncer de piel son tratables si se detectan precozmente, lo que subraya la necesidad de identificar la enfermedad con prontitud. 
La detección precoz no sólo salva vidas, sino que también evita que la enfermedad se vuelva peligrosa, desfigurante o incluso mortal.

\section*{Teledermatología}

Las imágenes dermatológicas se utilizan para detectar el cáncer de piel, mediante el análisis de las lesiones cutáneas y la pigmentación. Esta es una técnica 
utilizada para examinar las lesiones cutáneas mediante un instrumento manual denominado dermatoscopio, que amplía la piel hasta 10 veces. Con el avance de la 
tecnología, la atención sanitaria ha experimentado una transformación. Se ha producido un aumento de dispositivos de diagnóstico y se ha desplazado hacia el 
desarrollo de nuevas competencias en estadística y psicología de la toma de decisiones médicas.

La teledermatología comenzó a ganar terreno en la década de 2000 como una manera de proporcionar consulta dermatológica a distancia. Un trabajo pionero 
es el de Whited et al \cite{whited2002teledermatology}, que exploró la eficacia de la teledermatología en 2002. El estudio constató que la teledermatología 
reducía significativamente el tiempo de intervención de los pacientes, con una mediana de 5 días para las derivaciones teledermatológicas frente a 28 días para 
las derivaciones tradicionales. El estudio también constató que la teledermatología era especialmente eficaz para pacientes con afecciones urgentes o semi-urgentes. 
El artículo destaca las posibles ventajas de la teledermatología para mejorar el acceso a la asistencia y reducir los tiempos de espera de los pacientes.


\section*{Técnicas tempranas de clasificación de imágenes} 

Antes del auge de las redes neuronales y del aprendizaje profundo, había varias técnicas tradicionales utilizadas para la clasificación de imágenes. Estas técnicas se 
basaban en la extracción manual de características y en métodos de aprendizaje automático clásicos. La clave de la clasificación tradicional de imágenes radica en la 
extracción efectiva de características. Estas características deberían ser invariantes a pequeñas transformaciones y variaciones en las imágenes. Principalmente se tenía en cuenta:


\begin{enumerate}
    \item El Histograma de Gradientes Orientados (HOG): Esta técnica captura la distribución de direcciones de gradientes (orientaciones) en una imagen. \textit{add reference}
    
    \item Scale-Invariant Feature Transform (SIFT): Es utilizado para la detección y descripción de características locales en imágenes. El descriptor SIFT es invariante a cambios de escala, rotación y parcialmente invariante a cambios de punto de vista y afín. \textit{add reference}
    
    \item Binary Robust Independent Elementary Features (BRIEF): Es un descriptor de características que utiliza un conjunto de pruebas binarias para describir una región de interés en una imagen. \textit{add reference}
    
    \item Color Histograms: describen la distribución de colores en una imagen y son útiles para tareas en las que el color es un indicador importante. \textit{add reference}
\end{enumerate}

En 1974, se publicó un artículo en "IEEE Transactions on Automatic Control" %\cite{1100578}
relacionado con el reconocimiento de patrones y el aprendizaje automático, lo que indica que ya en la década de 1970 se estaban explorando estas técnicas para el reconocimiento de patrones en datos.

Con el tiempo, los investigadores comenzaron a aplicar algoritmos de aprendizaje automático tradicionales como Máquinas de Soporte Vectorial (SVM) y 
Árboles de Decisión para clasificar imágenes %\cite{lorente2021image} 
basándose en características extraídas manualmente. Esta ha logrado grandes avances en las últimas décadas en las siguientes tres áreas: (1) desarrollo y uso de algoritmos de clasificación avanzados, como algoritmos de clasificación de subpíxeles, por campo y basados en el conocimiento; (2) uso de múltiples funciones de teledetección, incluida información espectral, espacial, multitemporal y multisensor; y (3) incorporación de datos auxiliares en los procedimientos de clasificación, incluidos datos como topografía, suelo, carreteras y datos censales. La evaluación de la precisión es una parte integral de un procedimiento de clasificación de imágenes. La evaluación de la precisión basada en la matriz de errores es el enfoque más comúnmente empleado para evaluar la clasificación por píxel, mientras que los enfoques difusos están ganando atención para evaluar los resultados de la clasificación difusa. %\cite{lu2007survey}.

Otro algoritmo de machine learning utilizado en las primeras etapas de la clasificación de imágenes es el árbol de decisión. Los árboles de decisión son un tipo de algoritmo de aprendizaje supervisado que se utiliza para la clasificación y la regresión. En el contexto de la clasificación de imágenes, un árbol de decisión podría usarse para tomar decisiones basadas en ciertos criterios, como el color, la forma, el tamaño, etc., para clasificar una imagen en una categoría específica.

Con el tiempo, se introdujeron otros algoritmos de aprendizaje automático como los Clasificadores de Bosques Aleatorios, y Clasificadores de Bayes Ingenuos, que 
también se aplicaron a la clasificación de imágenes utilizando características manuales.A medida que se avanzaba, se desarrollaron técnicas más avanzadas como las Redes Neuronales Artificiales y, eventualmente, las Redes Neuronales Convolucionales (CNN), que mostraron una capacidad significativa para aprender características directamente de los datos, reduciendo así la necesidad de extracción manual de características %\cite{ml-techniques}.

\section*{Introducción y Desarrollo de Redes Neuronales}

Las primeras aplicaciones de redes neuronales en imágenes médicas se orientaron hacia el análisis y clasificación de dichas imágenes para apoyar 
en diagnósticos y tratamientos. 

\subsection*{Análisis de imágenes médicas}

El análisis de imágenes médicas mediante redes neuronales se ha enfocado en campos como ultrasonido, resonancia magnética, medicina nuclear y radiología, permitiendo la identificación y clasificación de patologías o condiciones específicas. Además, estas tecnologías han encontrado aplicaciones en áreas como la oftalmología, para el diagnóstico de enfermedades oculares a partir de imágenes de retina, y en la cardiología, para la evaluación de imágenes de ecocardiogramas. %\cite{unal2023doc}

\begin{description}
    \item[Ultrasonido]: La aplicación de redes neuronales en el ultrasonido ha mejorado significativamente la detección y caracterización de lesiones. Mediante el análisis automatizado de imágenes, se pueden identificar patrones sutiles que podrían pasarse por alto en la evaluación humana.
    
    \item[Resonancia Magnética (RM)]: En el ámbito de la RM, las redes neuronales han permitido un avance en la segmentación de imágenes, mejorando la precisión en la identificación de estructuras anatómicas y patológicas. Esto es especialmente relevante en la neurología, donde se utilizan para detectar y monitorizar enfermedades como la esclerosis múltiple.
    
    \item[Medicina Nuclear]: La aplicación de redes neuronales en medicina nuclear, como en la tomografía por emisión de positrones (PET), ha mejorado la interpretación de los estudios, permitiendo una detección más temprana y precisa de diversas patologías, incluyendo el cáncer.
    
    \item[Radiología]: En radiología, las redes neuronales han permitido el desarrollo de sistemas de ayuda al diagnóstico, especialmente en la detección de patologías pulmonares y mamarias. Estos sistemas pueden identificar anomalías en las radiografías y mamografías con un nivel de precisión que se acerca al de los especialistas humanos.
\end{description}
    
\subsection*{Clasificación y reconocimiento de patrones en imágenes médicas}  

Cuando se trata de la clasificación de imágenes, es esencial considerar que nuestro sistema visual humano (SVH) primero recibe las ondas electromagnéticas que pertenecen al espectro visible y luego las interpreta en el cerebro. Sin embargo, en el campo de la visión artificial, cuando introducimos una imagen en un ordenador, lo que se interpreta es una matriz de números generalmente en el rango de [0,255] y con tres dimensiones en caso de que sea una imagen a color (RGB). Como resultado, se puede notar una gran brecha entre el significado semántico de la clase asociada a una imagen y los valores de píxeles que la componen, lo que hace que la tarea de clasificación sea compleja para sistemas artificiales. 

En el ámbito de la medicina, se ha observado que la mayoría de los sistemas artificiales de diagnóstico, en un punto, toman decisiones que están cada vez menos relacionadas con la apariencia física de la imagen tal como la vería un radiólogo. En su lugar, estos sistemas se basan en los detalles del patrón matemático de las características físicas individuales de la imagen, que son extraídas por un sistema de visión artificial o un radiólogo, para tomar su decisión final. Estos patrones matemáticos han sido objeto de estudio durante décadas por científicos que han utilizado diversos métodos analíticos, incluyendo las redes neuronales. %\cite{unal2023doc}

Para abordar esta brecha entre la representación de la imagen y su significado, se han desarrollado varios tipos de algoritmos de clasificación. Algunos de estos algoritmos se basan en la detección de bordes, como el algoritmo de Canny %\cite{wikipedia2023canny}. 
Sin embargo, estos algoritmos son robustos cuando se trata de identificar una clase específica, pero si se desea clasificar una clase diferente, es necesario crear un nuevo modelo desde cero.

Otros algoritmos, como el k-Nearest Neighbors (KNN), se basan en medir la diferencia entre los valores de píxeles o distancias para comparar la similitud entre imágenes. Este enfoque es simple, pero requiere una configuración óptima de los hiperparámetros para obtener buenos resultados, lo que hace que estos algoritmos sean dependientes del problema que se está abordando.


Sin embargo, enfrentaron una serie de limitaciones significativas que restringieron su capacidad para abordar tareas complejas y desafiantes. La escasez de datos adecuados, la falta de recursos computacionales avanzados, arquitecturas simples, dificultades en el entrenamiento, generalización limitada, problemas de gradiente, falta de interpretabilidad y largos tiempos de entrenamiento fueron obstáculos clave en su desarrollo inicial.



Estas limitaciones condujeron a la necesidad de innovación y evolución en el campo de las redes neuronales. Esta necesidad llevó al surgimiento de un enfoque revolucionario en la forma de las Redes Neuronales Convolucionales (CNN), que abordaron muchas de estas limitaciones de manera efectiva.

\section*{Advenimiento de las redes neuronales convolucionales (CNN)}   

Mediante el uso de redes neuronales convolucionales, para facilitar la identificación de características relevantes en las imágenes médicas que pudieran ser indicativas de alguna condición médica particular las redes neuronales convolucionales han probado ser muy eficientes. Estas aprovecharon estructuras específicas de datos, como imágenes, para capturar patrones con mayor precisión, redujeron la carga computacional y mejoraron la generalización y la interpretabilidad. Gracias a estas mejoras, las CNN han sido fundamentales en el avance de la visión por computadora y han demostrado ser herramientas poderosas en una amplia variedad de aplicaciones, desde reconocimiento de objetos hasta diagnóstico médico. 

Una red neuronal convolucional está formada por diferentes capas, entre ellas las principales son las capas convolucionales, las capas de max-pooling, y las capas completamente conectadas.La capa convolucional tiene como objetivo realizar la convolución a la imagen de entrada, para extraer sus características. Realizar una convolución a una imagen, consiste en filtrar dicha imagen utilizando una máscara o ventana. La máscara se va desplazando por toda la imagen, multiplicándose de forma matricial. %\cite{unal2023doc}

Una revisión sistemática de 2018 destacó el uso de CNNs para clasificar lesiones cutáneas. En este estudio, se revisaron 13 artículos que utilizaban CNNs para la clasificación de lesiones cutáneas, y se encontró que los métodos más comunes eran aquellos que usaban una CNN ya entrenada con otro gran conjunto de datos y luego optimizaban sus parámetros para la clasificación de lesiones cutáneas. Las CNNs mostraron un alto rendimiento como clasificadores de lesiones cutáneas, aunque se señaló la dificultad de comparar diferentes métodos de clasificación debido a la utilización de conjuntos de datos no públicos en algunos casos. %\cite{brinker2018skin} 

Sin embargo, las técnicas de aprendizaje automático, incluidos los modelos de aprendizaje profundo, han surgido como herramientas prometedoras para el análisis 
de imágenes médicas, especialmente imágenes de lesiones cutáneas, para la detección del cáncer de piel melanoma. "A Deep Learning Approach to Skin Cancer Detection in Dermoscopy Images" %\cite{ameri2020deep} 
es un proyecto que sugiere un modelo de aprendizaje profundo para identificar cáncer de piel usando imágenes de lesiones en la piel. En esta investigación, se utilizaron 3400 imágenes de la colección de fotos dermatoscópicas HAM10000, que incluyen lesiones tanto melanoma como no melanoma. Se armó una red neuronal convolucional profunda para separar las imágenes en benignas y malignas. Se aplicó una técnica de aprendizaje transferido usando AlexNet como el modelo ya entrenado. El modelo sugerido toma la imagen tal cual es como entrada y descubre por su cuenta características valiosas en la imagen para clasificarla. Así, se salta los procesos complicados de segmentación de lesiones y extracción de características.

Un notable estudio publicado el 28 de octubre de 2022 publicado en Nature "Skin lesion classification of dermoscopic images using machine learning and convolutional neural network" %\cite{shetty2022skin}
se utilizó un subconjunto del conjunto de datos HAM10000 para clasificar lesiones cutáneas de imágenes dermatoscópicas y demostró la eficacia del uso de aprendizaje automático y redes neuronales convolucionales (CNN) en la clasificación de lesiones cutáneas a partir de imágenes dermatoscópicas. 
La metodología propuesta mostró resultados prometedores a la hora de distinguir entre lesiones malignas y benignas. El estudio compara la precisión de clasificación de distintos algoritmos de aprendizaje automático y modelos CNN. Se concluye que los modelos CNN proporcionan una mayor precisión en comparación con otros algoritmos de aprendizaje automático. En el sistema propuesto, alcanzan una precisión del 95,18\% con el modelo CNN.


Un artículo publicado en PubMed "An efficient deep learning-based skin cancer classifier for an imbalanced dataset" %\cite{alam2022efficient} 
propuso un eficaz clasificador de cáncer de piel basado en el aprendizaje profundo empleando el conjunto de datos HAM10000. Se utilizaron varios modelos de aprendizaje profundo como AlexNet, InceptionV3 y RegNetY-320 para clasificar el cáncer de piel. El rendimiento del marco propuesto fue mejor que el de los métodos convencionales. La precisión, la puntuación F1 y el valor de la curva ROC obtenidos con el marco propuesto fueron del 91\%, el 88,1\% y el 0,95. 

\section*{Técnicas modernas y avances recientes}

El avance en la detección de cáncer mediante el uso de la inteligencia artificial (IA) y el aprendizaje automático (ML) ha sido significativo en 
las últimas décadas, el mismo, ha demostrado un rendimiento excepcional en tareas de reconocimiento de imágenes, que es fundamental en la detección 
del cáncer de piel. Se llevó a cabo una revisión exhaustiva para evaluar el impacto de las técnicas de aprendizaje profundo en la detección precoz, 
en la que se analizaron diversos resultados de investigación y se presentaron mediante herramientas, gráficos, tablas y marcos para comprender mejor 
las técnicas predominantes en este campo %\cite{dildar2021skin}


Además, se introdujo un enfoque innovador de combinación de técnicas de aprendizaje automático y aprendizaje profundo para abordar el 
problema de la detección del cáncer de piel %\cite{tembhurne2023skin}.
 El modelo de aprendizaje profundo en este estudio empleó redes neuronales de última generación para extraer características de las imágenes, mientras que el modelo de aprendizaje automático procesó estas características de la imagen para clasificar las lesiones cutáneas.


En otro artículo publicado en PubMed "Design and validation of a new machine-learning-based diagnostic tool for the differentiation of dermatoscopic skin cancer images" \cite{tajerian2023design}
 se presentó un enfoque metodológico para mejorar el diagnóstico de la lesiones cutáneas pigmentadas utilizando imágenes dermatoscópicas del conjunto de datos HAM10000. Este conjunto de datos, una colección de 10015 imágenes dermatoscópicas recogidas a lo largo de 20 años, se utilizó para analizar lesiones cutáneas pigmentadas. l modelo obtiene los mejores resultados en la detección de lesiones de nevos melanocíticos,con una puntuación F1 de 0,93. La puntuación F1 para queratosis actínica, carcinoma basocelular, queratosis benigna, dermatofibroma, melanoma y lesiones vasculares fue consecutivamente de 0,63, 0,72, 0,70, 0,54, 0,58 y 0,80.


\section*{Retos y limitaciones actuales}

\subsection*{Dificultades en la interpretación de resultados y la falta de explicabilidad de los modelos}

Uno de los desafíos más significativos en el uso de algoritmos avanzados de aprendizaje automático y aprendizaje profundo es la interpretación y explicabilidad de sus resultados. Aunque estos modelos pueden lograr un alto grado de precisión, a menudo operan como "cajas negras", lo que significa que sus procesos internos y la forma en que llegan a una conclusión específica no son transparentes ni fácilmente comprensibles para los humanos. Esta falta de transparencia puede ser un obstáculo importante en el ámbito clínico, donde los profesionales de la salud necesitan comprender el razonamiento detrás de un diagnóstico para confiar y actuar según los resultados proporcionados por estos sistemas. %\cite{uam2023doc}


\subsection*{Problemas relacionados con el sobreajuste y la generalización de los modelos}
Otro reto importante es el sobre-ajuste y la generalización de los modelos. El sobre-ajuste ocurre cuando un modelo se ajusta demasiado a los datos de entrenamiento, perdiendo la capacidad de generalizar a nuevos datos. Este problema es particularmente prevalente en situaciones donde los conjuntos de datos de entrenamiento son limitados o no representativos de la variabilidad real de casos clínicos. Por ejemplo, la falta de diversidad en los tipos de piel y las características de las lesiones en los conjuntos de datos puede llevar a modelos que no se desempeñan bien en poblaciones no representadas durante el entrenamiento. %\cite{uam2023doc}

\subsection*{Limitaciones de los métodos tradicionales de aprendizaje automático en diagnóstico clínico}
Aunque los métodos tradicionales de aprendizaje automático, como las Máquinas de Vectores de Soporte (SVM), XGBoost y árboles de decisión, han sido útiles en la clasificación del cáncer de piel, enfrentan limitaciones significativas en el contexto clínico. Estos métodos requieren la extracción manual de características de las imágenes de enfermedades de la piel, un proceso que puede ser subjetivo y limitante. Además, la selección restringida de características puede impedir que estos algoritmos capturen la complejidad y variabilidad de las lesiones cutáneas, limitando su capacidad para generalizar a un espectro más amplio de tipos de cáncer de piel.%\cite{uam2023doc}

\subsection*{Escasez de datos y variedad limitada en categorías de cáncer de piel}
La escasez de datos y la limitada variedad en las categorías de cáncer de piel presentes en los conjuntos de datos disponibles son problemas centrales en el desarrollo de algoritmos efectivos para la clasificación del melanoma. Esta limitación en los datos disponibles afecta negativamente la capacidad de los modelos para aprender y reconocer una amplia gama de manifestaciones del cáncer de piel, lo que puede resultar en un rendimiento deficiente al enfrentarse a casos menos comunes o atípicos en la práctica clínica real.%\cite{uam2023doc}

\section*{Conclusión del estado del arte}

Los estudios revisados reflejan un claro progreso en la aplicación de CNNs y otras técnicas de aprendizaje profundo, no solo en términos de eficacia sino también en la reducción de tiempos de espera y mejora en el acceso a diagnósticos. Es notable cómo estos avances han permitido el desarrollo de sistemas de clasificación más robustos y precisos, capaces de distinguir entre lesiones cutáneas malignas y benignas con altos niveles de precisión.

En el contexto de estos avances, esta investigación aporta un valor distintivo en varios aspectos. Primero, la implementación de una arquitectura EfficientNetB5 para la clasificación de cáncer de piel, una técnica relativamente reciente y menos explorada en la literatura comparada con modelos más establecidos como AlexNet o InceptionV3. Esta elección representa un intento de equilibrar la eficiencia y precisión en un campo donde la carga computacional y la exactitud son críticas.

Además, el enfoque de esta investigación hacia el tratamiento de conjuntos de datos desequilibrados aborda una limitación significativa que ha sido un desafío persistente en estudios anteriores. Al proponer y validar métodos que manejan de manera efectiva la desproporción en las categorías de datos, se está contribuyendo a un área de necesidad crítica, mejorando potencialmente la capacidad del modelo para generalizar y funcionar eficazmente en escenarios clínicos reales.

Finalmente, esta investigación propone un análisis detallado de la interpretabilidad y la explicabilidad del modelo propuesto, un área que ha sido tradicionalmente un desafío en el campo de la inteligencia artificial. Entender cómo y por qué el modelo toma ciertas decisiones es crucial no solo para la confianza de los médicos y pacientes en estas tecnologías, sino también para identificar áreas de mejora y refinamiento en futuros trabajos.