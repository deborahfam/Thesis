\chapter{Estado del Arte}\label{chapter:state-of-the-art}

En las últimas décadas, los avances en potencia computacional han permitido un progreso significativo en el análisis automatizado de imágenes. Se ha pasado del análisis básico de imágenes digitales a sofisticados algoritmos capaces de identificar patrones sutiles en las imágenes de lesiones cutáneas. Los progresos en el reconocimiento de melanomas a partir de imágenes dermatológicas, han demostrado que los sistemas automatizados pueden lograr un diagnóstico comparable al de los expertos humanos \brackcite{DuHarpur2020}.   

\section{Teledermatología}

La teledermatología, una rama emergente de la telemedicina, ha revolucionizado el campo de la atención dermatológica. Impulsada por el auge de las tecnologías digitales a finales del siglo XX, esta modalidad se ha consolidado como una herramienta vital en el diagnóstico y manejo de afecciones cutáneas. Desde la década de 2000, la teledermatología ha permitido consultas dermatológicas remotas, ampliando significativamente el alcance de los servicios de salud \brackcite{romero2018practice}.

La investigación de Whited et al., en 2002, fue pionera en demostrar la efectividad de esta práctica \brackcite{whited2002teledermatology}. El estudio resaltó una reducción notable en los tiempos de respuesta, con una mediana de 5 días para consultas teledermatológicas, en contraste con los 28 días de los métodos tradicionales. Además, se enfatizó su utilidad en casos urgentes o semi-urgentes.

Paralelamente, la teledermatopatología ha mostrado su potencial, ofreciendo una fiabilidad comparable a la evaluación histológica tradicional \brackcite{romero2018practice}. Uno de los usos importantes de esta técnica fue detectar cáncer de piel. Un estudio, Piccolo et al., \brackcite{piccolo2002concordance} publicado en 2002, se centró en la concordancia entre los diagnósticos telepatológicos e histopatológicos convencionales, indicando contribuciones significativas en el campo de la teledermatopatología. Por término medio, el 78\% de los telediagnósticos fueron correctos (intervalo, 60\%-95\%), mientras que el 85\% de los diagnósticos convencionales fueron correctos (intervalo, 60\%-95\%). Se obtuvo una concordancia diagnóstica perfecta en 7 (35\%) de los 20 casos, y sólo se identificó una diferencia significativa en 1 caso.

Este avance en la teledermatología ha sentado las bases para la siguiente etapa en la medicina digital: el desarrollo de algoritmos computarizados que puedan detectar características en las imágenes, imitando el comportamiento humano, para luego a partir de estos obtener resultados.

\section{Técnicas tempranas de clasificación de imágenes} 

Cuando se trata de la clasificación de imágenes, es esencial considerar que nuestro sistema visual humano (SVH) primero recibe las ondas electromagnéticas que pertenecen al espectro visible y luego las interpreta en el cerebro. Sin embargo, en el campo de la visión artificial, cuando introducimos una imagen en un ordenador, lo que se interpreta es una matriz de números generalmente en el rango de [0,255] y con tres dimensiones en caso de que sea una imagen a color (RGB). Como resultado, se puede notar una gran brecha entre el significado semántico de la clase asociada a una imagen y los valores de píxeles que la componen, lo que hace que la tarea de clasificación sea compleja para sistemas artificiales \brackcite{unal2023doc}.

El reconocimiento de imágenes es una faceta de la inteligencia artificial que posibilita que los sistemas informáticos analicen e interpreten el contenido visual en imágenes. Esto se consigue detectando patrones y características distintivas que luego se emplean para clasificar y etiquetar objetos. Su propósito es automatizar el análisis visual, optimizando tiempo y recursos en diversas aplicaciones \brackcite{Qindel2023}. Esta tecnología se sustenta en algoritmos de aprendizaje automático, que entrenan a las máquinas para reconocer patrones visuales. Mediante el uso de bases de datos de imágenes etiquetadas para el entrenamiento, los algoritmos aprenden a identificar objetos y patrones. Una vez completado el entrenamiento, el modelo puede identificar automáticamente estos elementos en nuevas imágenes.

Desde finales del siglo XX, los ingenieros han dedicado esfuerzos significativos al desarrollo de técnicas y algoritmos para la categorización y reconocimiento de eventos a través de datos. Inicialmente, esto se centró en el procesamiento de texto para la clasificación automática de documentos, seguido por el tratamiento de sonidos e imágenes en diversos formatos. 

Un hito importante fue la publicación de un artículo sobre reconocimiento de patrones en 1974 en \textit{IEEE Transactions on Automatic Control} \brackcite{1100578}, evidenciando que ya en la década de $1970$ se estaban implementando estas técnicas en el reconocimiento de patrones. Los trabajos de este enfatizaron avances teóricos y experimentales significativos que impulsaron el progreso en el reconocimiento automático de patrones y el aprendizaje automático.

\subsection{Clasificación y reconocimiento de patrones en imágenes médicas}  

En el ámbito de la medicina, se ha observado que la mayoría de los sistemas artificiales de diagnóstico, en un punto, toman decisiones que están cada vez menos relacionadas con la apariencia física de la imagen tal como la vería un radiólogo. En su lugar, estos sistemas se basan en los detalles del patrón matemático de las características físicas individuales de la imagen, que son extraídas por un sistema de visión artificial o un radiólogo, para tomar su decisión final. Estos patrones matemáticos han sido objeto de estudio durante décadas por científicos que han utilizado diversos métodos analíticos, incluyendo las redes neuronales \brackcite{unal2023doc}.

Para abordar esta brecha entre la representación de la imagen y su significado, se han desarrollado varios tipos de algoritmos de clasificación. Algunos de estos algoritmos se basan en la detección de bordes, como el algoritmo de Canny \brackcite{datamount2023}. Sin embargo, estos algoritmos son robustos cuando se trata de identificar una clase específica, pero si se desea clasificar una clase diferente, es necesario crear un nuevo modelo desde cero \brackcite{rong2014improved}.

Esta serie de limitaciones restringieron su capacidad para abordar tareas complejas y desafiantes. La escasez de datos adecuados, la falta de recursos computacionales avanzados, arquitecturas simples, dificultades en el entrenamiento, generalización limitada, problemas de gradiente, falta de interpretabilidad y largos tiempos de entrenamiento fueron obstáculos clave en su desarrollo inicial.

Técnicas utilizadas en los inicios para la clasificación de patrones rompieron con algunas de las barreras de desarrollo: histograma de gradientes orientados (HOG) \brackcite{datasmarts_hog_scikit_image_2020}, Scale-Invariant Feature Transform (SIFT) \brackcite{lindeberg2012scale}, Binary Robust Independent Elementary Features (BRIEF) \brackcite{calonder2010brief}, Color Histograms \brackcite{pinecone_color_histograms}, entre otras. En la bibliografía se encuentran métodos de bajo nivel como son segmentación de la imagen por niveles grises, bordes o formas, entre otros y métodos de alto nivel como clasificadores basados en redes neuronales, máquinas de soporte vectorial (SVM), árbol de decisiones, entre otros \brackcite{leiva2019tecnicas}. 

Se destaca, además, que las tres técnicas más usadas en la clasificación automática de imágenes son árboles de decisiones, redes neuronales y máquinas de vectores de soporte siendo las redes neuronales una de las más utilizadas en campo del aprendizaje profundo \brackcite{leiva2019tecnicas}. 

\section{Introducción y desarrollo de \textit{machine learning} en el campo médico}

Las primeras aplicaciones de redes neuronales en imágenes médicas se orientaron hacia el análisis y clasificación de dichas imágenes para apoyar 
en diagnósticos y tratamientos. 

\subsection{Análisis de imágenes médicas}

El análisis de imágenes médicas mediante redes neuronales se ha enfocado en campos de la medicina como resonancia magnética, medicina nuclear y radiología, permitiendo la identificación y clasificación de patologías o condiciones específicas. Además, estas tecnologías han encontrado aplicaciones en áreas como la oftalmología, para el diagnóstico de enfermedades oculares a partir de imágenes de retina, y en la cardiología, para la evaluación de imágenes de ecocardiogramas \brackcite{unal2023doc}.

\begin{description}   
    \item Resonancia Magnética: En el contexto de la esclerosis múltiple, se han explorado soluciones de segmentación basadas en redes neuronales convolucionales (CNNs) para segmentaciones rápidas y fiables de lesiones y estructuras de materia gris en imágenes de resonancia magnética multimodal \brackcite{lee2022analysis}.
    
    \item Medicina Nuclear:  En este campo un estudio demuestra cómo el aprendizaje profundo puede restaurar la calidad de imagen diagnóstica y mantener la precisión de la cuantificación de SUV para exploraciones PET con un conteo reducido, lo que podría aumentar la seguridad y reducir el costo de las imágenes PET \brackcite{chaudhari2021low}.
    
    \item Radiología: En radiología, la aplicación de la inteligencia artificial en el análisis de imágenes de cáncer, con un enfoque en radiomía y representaciones derivadas del aprendizaje profundo, y su uso para el soporte de decisiones en la gestión del cáncer \brackcite{bera2022predicting}.
\end{description}

Esto muestra que el análisis de imágenes médicas a través de redes neuronales representa un avance significativo en diversas áreas de la medicina. Las aplicaciones van desde la identificación de patologías en resonancia magnética, medicina nuclear y radiología, hasta el diagnóstico de enfermedades oculares y la evaluación cardíaca. Estas tecnologías no solo mejoran la precisión en la detección y clasificación de condiciones específicas, sino que también optimizan la eficiencia de los procesos diagnósticos y terapéuticos, destacando el papel crucial de la inteligencia artificial en el futuro de la medicina. 

Teniendo en cuenta utilizando la inteligencia artificial se puede procesar grandes cantidades de datos, resulta una opción inteligente y acertada la recopilación de grandes volúmenes de datos (relacionados entre sí) para el procesamiento de los mismos con alguna herramienta de ML.

\section{Datasets de cáncer de piel}

En el campo de la dermatología, la generación de imágenes clínicas y dermatoscópicas es una práctica común para supervisar los cambios en las condiciones de la piel. Estas imágenes se han vuelto un recurso crucial para el avance de algoritmos de aprendizaje automático, especialmente en el desarrollo de Redes Neuronales Convolucionales (CNN). Los datasets son esenciales en ML porque proporcionan la base sobre la cual los algoritmos aprenden, se prueban, se comparan y evolucionan, permitiendo así la aplicación práctica y la innovación continua en este campo. Existen varios conjuntos de datos accesibles para la investigación en este ámbito.

Wu et al., recoge en su estudio un conjunto de los dataset de imágenes dermatologicas más utilizados en algoritmos de clasificación que se exponen a continuación:

\begin{itemize}
    \item El PH2 Dataset, compuesto por 200 imágenes dermoscópicas de tres tipos de enfermedades de la piel es ampliamente utilizado para probar algoritmos de diagnóstico de enfermedades de la piel, mostrando altas tasas de precisión en varios estudios \brackcite{wu2022skin}. 
    \item MED-NODE Dataset: Contiene 170 imágenes digitales de melanoma y nevus. Diversos métodos han mostrado resultados significativos de clasificación en este dataset \brackcite{wu2022skin}.
    \item HAM10000 Dataset: Recopilado por ISIC, incluye 10,015 imágenes dermoscópicas de siete enfermedades representativas de lesiones cutáneas pigmentadas. Se utiliza ampliamente en estudios de clasificación de cáncer de piel, superando a menudo el nivel de diagnóstico de los dermatólogos \brackcite{wu2022skin}.
    \item Derm7pt Dataset: Contiene aproximadamente 2,000 imágenes clínicas y de dermoscopia de enfermedades de la piel. Se ha utilizado para probar diversas redes multitarea y métodos de clasificación \brackcite{wu2022skin}.
    \item BCN20000 Dataset: Compuesto por 5,583 lesiones cutáneas y 19,424 imágenes dermoscópicas. Se emplea comúnmente en tareas de clasificación y segmentación de cáncer de piel \brackcite{wu2022skin}.
    \item ISIC Dataset: Con más de 13,000 imágenes dermoscópicas, se enfoca en la clasificación y segmentación del cáncer de piel, siendo utilizado en numerosos estudios y competiciones \brackcite{wu2022skin}.
\end{itemize}

Mientras que, entre otros autores Das et al., \brackcite{das2021machine} también menciona otros conjuntos de datos relevantes incluyen el Atlas Interactivo de Dermoscopia con 1000 ejemplos clínicos \brackcite{das2021machine}, la Biblioteca de Imágenes Dermofit con 1300 fotografías de alta resolución \brackcite{das2021machine}, el conjunto de datos de Asan \brackcite{das2021machine}, con 17,125 fotos clínicas, y el Hallym \brackcite{das2021machine}, con 125 fotos de casos de carcinoma basocelular. Además, los conjuntos de datos SD-198 y SD-260 \brackcite{das2021machine} ofrecen una amplia gama de imágenes clínicas de diversas enfermedades de la piel. Dermnet NZ y Derm7pt \brackcite{das2021machine} proporcionan colecciones extensas de fotografías clínicas, dermatoscópicas e histológicas, y The Cancer Genome Atlas \brackcite{das2021machine} presenta una de las mayores colecciones de diapositivas de lesiones cutáneas patológicas.

Entre todos estos conjuntos de datos, el HAM10000 se destaca por su amplia utilización en la investigación del cáncer de piel. Este conjunto de datos es particularmente valioso debido a su extensa colección de imágenes de lesiones de piel, que incluye una variedad de tipos de cáncer de piel. Su uso generalizado en la comunidad científica y su relevancia en estudios recientes lo convierten en el dataset ideal para el desarrollo de esta tesis. La riqueza y diversidad de las imágenes en HAM10000 proporcionan una base sólida para entrenar y evaluar algoritmos de \textit{machine learning}.

\section{Redes neuronales convolucionales en la medicina}   
El avance en la clasificación y detección de enfermedades de la piel, impulsado por los conjuntos de datos como HAM10000, ha preparado el camino para aplicaciones más sofisticadas en el análisis de imágenes médicas. En este escenario, las Redes Neuronales Convolucionales (CNN) emergen como una herramienta esencial, aprovechando la profundidad y variedad de los datos disponibles. Estas redes son especialmente eficaces en tareas de reconocimiento y clasificación visual, gracias a su capacidad para procesar y aprender de grandes volúmenes de imágenes.

Una red neuronal convolucional está formada por diferentes capas, entre ellas las principales son las capas convolucionales, las capas de max-pooling, y las capas completamente conectadas.La capa convolucional tiene como objetivo realizar la convolución a la imagen de entrada, para extraer sus características. Realizar una convolución a una imagen, consiste en filtrar dicha imagen utilizando una máscara o ventana. La máscara se va desplazando por toda la imagen, multiplicándose de forma matricial \brackcite{unal2023doc}.

En el campo de la medicina, estas facilitan la identificación de características relevantes en las imágenes médicas que pudieran ser indicativas de alguna condición médica particular. Se aprovechan de estructuras específicas de datos, como imágenes, para capturar patrones con mayor precisión, reducir la carga computacional y mejorar la generalización y la interpretabilidad. 

La evolución en la clasificación de lesiones cutáneas ha estado marcada por el uso innovador de redes neuronales convolucionales (CNNs). Una revisión sistemática en 2018 por Brinker et al., \brackcite{brinker2018skin} analizó 13 artículos que implementaban CNNs para esta tarea, destacando su alto rendimiento. Los enfoques más comunes involucraron la reutilización de CNNs ya entrenadas con grandes conjuntos de datos, optimizadas posteriormente para la clasificación específica de lesiones cutáneas. Esta metodología, aunque efectiva, enfrentó retos como la dificultad de comparar distintos métodos debido a la variabilidad en los conjuntos de datos.

Posteriormente, las técnicas de aprendizaje automático, y en particular los modelos de aprendizaje profundo, emergieron como herramientas poderosas para el análisis de imágenes médicas. Un proyecto clave fue \textit{A Deep Learning Approach to Skin Cancer Detection in Dermoscopy Images} \brackcite{ameri2020deep}, donde se utilizó un conjunto de 3400 imágenes dermatoscópicas del HAM10000, incluyendo lesiones melanoma y no melanoma. Se implementó una red neuronal convolucional profunda que procesaba imágenes directamente, identificando características valiosas sin necesidad de segmentación previa, lo cual representó un avance significativo en la simplificación y eficacia del proceso de clasificación.

En 2022, el estudio \textit{Skin lesion classification of dermoscopic images using machine learning and convolutional neural network} \brackcite{shetty2022skin}, publicado en Nature, utilizó un subconjunto del HAM10000 para clasificar lesiones cutáneas mediante aprendizaje automático y CNN. Este enfoque ofreció resultados prometedores en la distinción entre lesiones malignas y benignas, logrando una precisión del 95,18\% con el modelo CNN. La comparación con otros algoritmos de aprendizaje automático resaltó la superioridad de los modelos CNN en términos de precisión.

Tajerian , \brackcite{tajerian2023design} presentó un enfoque metodológico para mejorar el diagnóstico de la lesiones cutáneas pigmentadas utilizando imágenes dermatoscópicas del conjunto de datos HAM10000. Este conjunto de datos se utilizó para analizar lesiones cutáneas pigmentadas. El modelo obtiene los mejores resultados en la detección de lesiones de nevos melanocíticos,con una puntuación F1 de 0,93.

Adegun et al., \brackcite{adegun2021deep} recoge un conjunto de artículos que contribuyeron al desarrollo de algoritmos además de los anteriormente mencionados. Las referencias a los siguientes artículos están recogidas en el mismo \brackcite{adegun2021deep}:

\begin{enumerate}
    \item Majtner et al., usaron técnicas de CNN para la extracción de características y preprocesamiento, utilizando el conjunto de datos ISIC con 900 muestras de entrenamiento y 379 de prueba, clasificadas en benignas y malignas \brackcite{adegun2021deep}. 

    \item Vipin et al.,  implementaron un sistema de dos etapas, segmentación y clasificación, utilizando un conjunto de datos ISIC de 13,000 imágenes, reducido a 7,353 tras eliminar imágenes no utilizables \brackcite{adegun2021deep}. 

    \item Nasr-Esfahani et al.,  desarrollaron su propia CNN para preprocesar, extraer características y clasificar imágenes, con un conjunto de 170 imágenes no dermatoscópicas del UMCG, aumentado a 6,120 imágenes \brackcite{adegun2021deep}. 

    \item Attia et al., usaron una CNN completamente conectada con arquitecturas de autoencoder-decoder, alcanzando una precisión del 98\% y una especificidad del 94\% \brackcite{adegun2021deep}. 

    \item Mukherjee et al., desarrollaron una arquitectura CNN para la detección de lesiones malignas, logrando precisiones de 90.14\% y 90.58\% en los conjuntos de datos MEDNODE y Dermofit \brackcite{adegun2021deep}. 

    \item Sanketh et al., propusieron una CNN para la detección temprana de cáncer de piel, obteniendo un resultado óptimo del 98\% \brackcite{adegun2021deep}. 

    \item Rahi et al., propusieron un modelo CNN con varias capas convolucionales y de agrupación máxima, logrando una precisión del 84.76\% y una especificidad del 78.81\% \brackcite{adegun2021deep}. 

    \item Gulati et al., emplearon redes preentrenadas como AlexNet y VGG16, obteniendo mejores resultados con VGG16 en modo de aprendizaje transferido \brackcite{adegun2021deep}.
    \item Daghrir et al.,combinaron una CNN con técnicas de aprendizaje automático clásicas, alcanzando una precisión individual del 85.5\% con CNN \brackcite{adegun2021deep}. 

    \item Acosta et al., incorporaron técnicas de CNN basadas en máscaras y regiones con una estructura ResNet152 preentrenada, logrando una precisión del 90.4\% y una especificidad del 92.5\% \brackcite{adegun2021deep}.

\end{enumerate}

El avance en la detección de cáncer mediante el uso de la inteligencia artificial (IA) y el aprendizaje automático (ML) ha sido significativo en las últimas décadas. El mismo ha demostrado un rendimiento excepcional en tareas de reconocimiento de imágenes, que es fundamental en la detección del cáncer de piel. Se llevó a cabo una revisión exhaustiva para evaluar el impacto de las técnicas de aprendizaje profundo en la detección precoz, en la que se analizaron diversos resultados de investigación y se presentaron mediante herramientas, gráficos, tablas y marcos para comprender mejor las técnicas predominantes en este campo \brackcite{dildar2021skin}.

\section {Trabajos basados en EfficientNet}

Uno de los modelos de redes convolucionales que ha tenido relevacia es EfficientNet. Este es una familia de modelos de red neuronal convolucional diseñada para la eficiencia, que significa que pueden lograr una mayor precisión con menos parámetros y computación. Es un novedoso método de escalado de modelos que utiliza un coeficiente compuesto sencillo pero muy eficaz para escalar las CNN de forma más estructurada \brackcite{tan2019efficientnet}.

Un estudio innovador relacionado con EfficientNet es el de Ali et al., \brackcite{ali2022multiclass}. Este desarrolló una cadena de procesamiento de imágenes previo al entrenamiento, que incluía la eliminación de cabellos en las imágenes, el aumento de datos y el redimensionamiento de las imágenes para cumplir con los requisitos de cada modelo de CNN. Utilizando transferencia de aprendizaje con pesos pre-entrenados de ImageNet y ajuste fino de las redes, se entrenaron variantes de EfficientNet (B0-B7) en el conjunto de datos HAM10000. El modelo más exitoso, EfficientNet B4, alcanzó una puntuación F1 y una precisión Top-1 del 87\% y 87.91\%, respectivamente, destacando que una complejidad intermedia del modelo puede ser óptima para este tipo de tareas. El modelo en cuestión relacionado con nuestro enfoque (EfficientNetB1) obtuvo una precisión del 86.5\% y una precisión Top-1 del 86.5\%.

Por otro lado Papiththira et al. \brackcite{papiththira2021melanoma} se centró específicamente en la detección de melanoma utilizando un enfoque basado en transferencia de aprendizaje profundo sin necesidad de preprocesamiento de imágenes. Este método se apoyó en el modelo EfficientNet pre-entrenado, complementado con un módulo de atención de canales para resaltar características específicas del melanoma en la clasificación. Evaluado en los conjuntos de datos UMGC y HAM10000, que incluyen imágenes clínicas y dermoscópicas, el enfoque propuesto superó los métodos del estado del arte con una precisión de clasificación del 84.12\% y 96.32\%, respectivamente.

\section{Conclusión del estado del arte}

Es notable un progreso en el análisis automatizado de imágenes, especialmente en el ámbito médico. Este avance ha sido impulsado significativamente por el desarrollo en la potencia computacional y la inteligencia artificial, lo que ha facilitado un diagnóstico más preciso y rápido de enfermedades. Paralelamente, el campo de la dermatología ha experimentado una revolución con la introducción de la teledermatología y teledermatopatología, mejorando la accesibilidad a servicios especializados y permitiendo diagnósticos rápidos y precisos a distancia, lo que es esencial para el tratamiento oportuno de enfermedades cutáneas.

Además, se ha destacado la importancia de los conjuntos de datos en el aprendizaje automático, como el HAM10000, que han sido cruciales en el desarrollo de algoritmos en dermatología. Estos datasets proporcionan una base diversa y rica para el entrenamiento y evaluación de modelos, contribuyendo a avances significativos en la clasificación y detección de enfermedades de la piel. En términos de técnicas de clasificación de imágenes, se ha observado una evolución desde métodos iniciales como el procesamiento de bordes hasta el uso de algoritmos avanzados de aprendizaje automático y profundo. Las redes neuronales, en particular, han mostrado ser herramientas excepcionales para el análisis de imágenes médicas, aumentando la precisión y eficiencia en la identificación de patologías.

El papel de las redes neuronales convolucionales (CNN) en medicina ha sido fundamental, especialmente en dermatología, donde han posibilitado avances significativos en la clasificación de lesiones cutáneas. Los modelos basados en CNN han alcanzado una precisión comparable a la de especialistas humanos, lo que sugiere un futuro prometedor para la inteligencia artificial en el diagnóstico y tratamiento de enfermedades.

Sin embargo, a pesar de estos avances, todavía persisten desafíos como la variabilidad en los conjuntos de datos y la necesidad de mejorar la generalización de los modelos. Estos retos ofrecen oportunidades para futuras investigaciones y desarrollos, en particular en la mejora de algoritmos y en la integración de nuevas tecnologías en la práctica médica.