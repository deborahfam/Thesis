
1- Por que si EfficientNet b4 tiene mejor precisión se utilizó EfficientNet b1?

A pesar de que EfficientNet B4 presenta una mayor precisión, su implementación conlleva un incremento significativo en el costo computacional, así como en la cantidad de hiper-parámetros y datos requeridos. La elección de EfficientNet B1 para nuestro proyecto se debió principalmente a limitaciones en la capacidad computacional disponible para el entrenamiento del modelo. Además, se determinó que, dado el conjunto de datos con el que contábamos, EfficientNet B1 era adecuado para lograr una clasificación precisa. Otro factor a considerar fue el riesgo de sobreajuste al emplear un modelo más complejo. En resumen, EfficientNet B1 resultó ser la opción más apropiada para las necesidades específicas de nuestro problema.

2- En que se basaron los parámetros seleccionados de regularización y de la estrategia de cambio de tasa de aprendizaje?

Para la regularización, se optó por implementar L1 y L2. La regularización L2 agrega un costo proporcional al cuadrado de los valores de los pesos, reduciendo el riesgo de sobre-ajuste al mantener los pesos relativamente bajos. La regularización L1, por su parte, agrega un costo basado en el valor absoluto de los pesos, favoreciendo un modelo más escaso y posiblemente más interpretable. Por lo que se utilizaron estos parámetros para lograr un modelo más preciso y evitar el sobre-ajuste. Los valores específicos de L2 (λ=0.016) y L1 (λ=0.006) se ajustaron manualmente durante los experimentos, buscando optimizar precisión y efectividad.

La estrategia de cambio de tasa de aprendizaje se adoptó para permitir ajustes dinámicos en respuesta al rendimiento del modelo, facilitando una optimización más eficiente y evitando variaciones excesivas en el espacio de soluciones. Esta estrategia ayuda a que el modelo no solo se ajuste a los datos de entrenamiento, sino que también generalice de manera efectiva. Con el ajuste de la tasa de aprendizaje, nuestro modelo no solo es más eficaz, sino que también emplea los recursos de cómputo de manera más eficiente, evitando el desperdicio de ciclos de entrenamiento en configuraciones que no mejoran el rendimiento.

3- Para las clases con menos elementos (Tabla 3.5 manuscrito) hay clases como la DF que solo tienen 115 elementos, se puede observar según la tabla que estos casos se utilizaron todos los elementos para el entrenamiento y a su vez algunos para validación. Explique en mas detalle este proceder  y en caso de ser así, explique brevemente que efecto puede tener esto sobre los resultados de precision?

En relación a las clases con menor número de elementos, como se muestra en la Tabla 3.5, es importante aclarar que la cantidad indicada corresponde únicamente al conjunto de entrenamiento. La estrategia adoptada buscaba equilibrar la cantidad de muestras en el entrenamiento para evitar el sobreajuste y el procesamiento excesivo debido al desbalance de datos. Por ende, en casos como el de las clases DF y VASC, el total de muestras incluye los conjuntos de entrenamiento, validación y prueba, sin que haya intersección entre ellos. Es crucial evitar dicha intersección para prevenir sesgos en los resultados, ya que entrenar y probar con los mismos elementos puede artificialmente inflar la precisión del modelo.

4- Cree que con preprocesamiento mas robusto (mejor nitidez ...) o con un aumento de parámetros del modelo se puedan mejorar los resultados?

Debido a la falta de recursos computacionales no se pueden hacer búsquedas mas exhaustivas para el ajuste de hiper-parámetros y encontrar una combinación de estos que de mejor resultados. Esto tambien forma parte de las recomendaciones del proyecto.

Tanto la mejora del preprocesamiento de imágenes como el aumento de los parámetros del modelo pueden ser vías efectivas para mejorar el rendimiento. Sin embargo, cada enfoque debe considerarse con cuidado. Aumentar la profundidad del modelo (más capas) puede permitir que el modelo aprenda características más complejas y abstractas. Sin embargo, esto también puede llevar a un mayor riesgo de sobreajuste, sobre todo con el desbalance de clases existente. Aumentar el ancho del modelo (más neuronas por capa) puede proporcionar una mayor capacidad de aprendizaje, pero de nuevo, esto puede resultar en sobreajuste y aumentar la necesidad de más datos para entrenar eficazmente el modelo.

Mejorar la nitidez y la calidad general de las imágenes puede ayudar al modelo a detectar características sutiles, lo cual es especialmente crítico en aplicaciones médicas donde los detalles finos pueden ser indicativos de condiciones patológicas. Un modelo solo es tan bueno como los datos con los que se entrena. 